{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST X RealNVP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2変量標準正規分布 -> MNIST\n",
    "\n",
    "\n",
    "| |データサイズ|\n",
    "|----| ----|\n",
    "| 2変量標準正規分布 | 2|    \n",
    "|MNIST | 28 x 28 x 1 |\n",
    "|CIFER10| h x w x 3|\n",
    "| Text | Seq_len x Embedding_size ? |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squeeze\n",
    "入力を $h * w * c$ としたときに、その次元数を $\\cfrac{h}{2} * \\cfrac{w}{2} * 4c$ とする手法\n",
    "\n",
    "すると、RealNVP のカップリングレイヤー上で、    \n",
    "黒い部分が $x_a$ 白い部分が $x_b$ の役割を果たすようになる。\n",
    "\n",
    "図では平面だが、3次元テンソルの場合も上から眺めることで、同様の平面として処理している。\n",
    "\n",
    "\n",
    "※ $1 * 1 * c'$ 以降に変換を重ねたい場合の処理についてはおそらく未定義 (RealNVPの論文を読む限り)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Scale Architecture\n",
    "![](./multi-scale-arch.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow を用いて解く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow:  2.0.0-rc0\n",
      "tensorflow-probability:  0.8.0-rc0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "print('tensorflow: ', tf.__version__)\n",
    "print('tensorflow-probability: ', tfp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目標分布を作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow             : shape: (2, 2, 256) mean: -0.015819 sd: 0.964981\n",
      "Tensorflow Probability : shape: (2, 2, 256) mean: 0.018457 sd: 0.984943\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow の distribution を使う場合\n",
    "z = tf.random.normal([2, 2, 256])\n",
    "print('Tensorflow             : shape: {} mean: {:.6f} sd: {:.6f}'.format(z.shape, tf.math.reduce_mean(z), tf.math.reduce_std(z)))\n",
    "# Tensorflow Probability の distribution を使う場合\n",
    "target_dist = tfd.Normal(loc=0., scale=1.)\n",
    "z = target_dist.sample([2, 2, 256])\n",
    "print('Tensorflow Probability : shape: {} mean: {:.6f} sd: {:.6f}'.format(z.shape, tf.math.reduce_mean(z), tf.math.reduce_std(z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 元分布(MNIST)データセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# From tensorflow's BEGINNER TUTORIALS\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.tobytes()]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "\n",
    "return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def _preprocess(x):\n",
    "    x = tf.pad(x, paddings=[[0, 0], [2, 2], [2, 2]], mode=\"CONSTANT\")\n",
    "    x = tf.expand_dims(x, axis=-1)\n",
    "    return x\n",
    "\n",
    "def create_mnist():\n",
    "    (train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data()\n",
    "    print('train_dataset: {} images'.format(train_x.shape[0]))\n",
    "    print('test_dataset : {} images'.format(test_x.shape[0]))\n",
    "    if not os.path.exists(\"mnists\"):\n",
    "        os.mkdir(\"mnists\")\n",
    "\n",
    "    def _serialize_example_pyfunction(img, label):\n",
    "        feature = {\n",
    "            \"img\": _bytes_feature(img.numpy()),\n",
    "            \"label\": _int64_feature(label.numpy()),\n",
    "        }\n",
    "        example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        return example_proto.SerializeToString()\n",
    "    \n",
    "    @tf.function\n",
    "    def _gen_tf_serialize_example(img, label):\n",
    "        tf_string = tf.py_function(\n",
    "            _serialize_example_pyfunction, (img, label), tf.string\n",
    "        )\n",
    "        return tf.reshape(tf_string, ())\n",
    "\n",
    "    def _save_features_dataset(save_to, feature_dataset):\n",
    "        serialized_feature_dataset = train_features_dataset.map(\n",
    "            _gen_tf_serialize_example\n",
    "        )\n",
    "        writer = tf.data.experimental.TFRecordWriter(save_to)\n",
    "        writer.write(serialized_feature_dataset)\n",
    "\n",
    "    train_x = _preprocess(train_x)\n",
    "    train_features_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "    _save_features_dataset(os.path.join('mnists', 'train.tfrecord'), train_features_dataset)\n",
    "    \n",
    "    test_x = _preprocess(test_x)\n",
    "    test_features_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
    "    _save_features_dataset(os.path.join('mnists', 'test.tfrecord'), test_features_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: 60000 images\n",
      "test_dataset : 10000 images\n"
     ]
    }
   ],
   "source": [
    "create_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データセットの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "feature_description  = {\n",
    "    'img': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64, default_value=0)\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    feature = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    img = tf.io.decode_raw(feature['img'], out_type=tf.uint8)\n",
    "    img = tf.reshape(img, [32, 32, 1])\n",
    "    img = tf.cast(img, dtype=tf.float32)\n",
    "    img = (img / (255.0 / 2)) - 1\n",
    "    feature['img'] = img\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TFRecordDatasetV2 shapes: (), types: tf.string>\n",
      "<MapDataset shapes: {img: (32, 32, 1), label: ()}, types: {img: tf.float32, label: tf.int64}>\n"
     ]
    }
   ],
   "source": [
    "filenames = [os.path.join('mnists', 'train.tfrecord')]\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "print(raw_dataset)\n",
    "parsed_dataset = raw_dataset.map(_parse_function) \n",
    "print(parsed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAPvElEQVR4nO3dfYxUZZbH8e+xBV8QFZZa0iLaM2jcEF2BlOBGo+hk1DWjSLIxGONbjJiNyJpADEqysol/OLpqVIymUSJsFGURImzMOmgwhpgwFIotiKwvaRwIL23wbTVZFc/+UZdMQ+rprq6qW9Xt+X2STlc9p27dkwu/vlX3Vj3X3B0R+fU7ptUNiEhzKOwiQSjsIkEo7CJBKOwiQSjsIkEcW8/CZnYV8ATQBjzn7g/19fgxY8Z4R0dHPasUkT50d3fz5ZdfWqVazWE3szbgaeD3wG5gs5mtdfePUst0dHRQKpVqXaWI9KNYLCZr9byMnwp86u6fu/uPwMvAjDqeT0RyVE/YxwF/6XV/dzYmIoNQ7gfozGy2mZXMrNTT05P36kQkoZ6w7wHG97p/ejZ2BHfvdPeiuxcLhUIdqxORetQT9s3A2Wb2GzMbDswC1jamLRFptJqPxrv7z2Y2B3iD8qm3pe6+vWGdiUhD1XWe3d1fB15vUC8ikiN9gk4kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kiLquCGNm3cB3wCHgZ3dPXwleRFqqrrBnLnP3LxvwPCKSI72MFwmi3rA78Ccz22JmsxvRkIjko96X8Re7+x4z+1tgvZl97O7v9H5A9kdgNsAZZ5xR5+pEpFZ17dndfU/2+wCwBpha4TGd7l5092KhUKhndSJSh5rDbmYjzGzk4dvAFcC2RjUmIo1Vz8v4scAaMzv8PC+5+383pCsRabiaw+7unwPnN7AXEcmRTr2JBKGwiwShsIsEobCLBKGwiwTRiC/CyBBw6NChZO2bb75p+PoWL15ccfyHH35ILrNz585k7emnn07W5s+fn6ytWLGi4vjxxx+fXGbBggXJ2gMPPJCsDXbas4sEobCLBKGwiwShsIsEobCLBKGj8S30xRdfJGs//vhjsvbuu+8maxs3bqw4/vXXXyeXWbVqVbLWTOPHj0/W7r777mRtzZo1ydrIkSMrjp9/fvprHZdeemmyNpRpzy4ShMIuEoTCLhKEwi4ShMIuEoTCLhKETr3l7P3330/WLr/88mQtjy+nDAZtbW3J2oMPPpisjRgxIlm78cYbk7XTTjut4vioUaOSy5xzzjnJ2lCmPbtIEAq7SBAKu0gQCrtIEAq7SBAKu0gQ/Z56M7OlwB+AA+5+bjY2GngF6AC6gevd/av82hy6zjzzzGRtzJgxydpgOfU2bdq0ZK2v01cbNmyoOD58+PDkMjfddFP1jcmAVbNnfwG46qixBcBb7n428FZ2X0QGsX7Dnl1v/eBRwzOAZdntZcB1De5LRBqs1vfsY919b3Z7H+UruorIIFb3ATp3d8BTdTObbWYlMyv19PTUuzoRqVGtYd9vZu0A2e8DqQe6e6e7F929WCgUalydiNSr1rCvBW7Jbt8CvNaYdkQkL9WcelsBTAfGmNlu4AHgIWClmd0O7AKuz7PJoWz06NHJ2iOPPJKsrVu3LlmbPHlysjZ37tzqGutl0qRJydqbb76ZrPX1TbRt27ZVHH/yySerb0waqt+wu/sNidLvGtyLiORIn6ATCUJhFwlCYRcJQmEXCUJhFwlCE0620HXXpb9S0NdklKnrlwF0dXVVHH/uueeSy8yfPz9Z6+v0Wl/OPffciuOdnZ01PZ/UT3t2kSAUdpEgFHaRIBR2kSAUdpEgFHaRIHTqbZA6+eSTa1rulFNOGfAyfZ2WmzVrVrJ2zDHaVwwl+tcSCUJhFwlCYRcJQmEXCUJhFwlCR+N/ZRYtWlRxfMuWLcll3n777WStrznorrjiimrbkkFAe3aRIBR2kSAUdpEgFHaRIBR2kSAUdpEgqrn801LgD8ABdz83G1sE3AEcvizr/e7+el5NSvVSc8YtWbIkucyUKVOStTvuuCNZu+yyy5K1YrFYcfyuu+5KLmNmyZrUr5o9+wvAVRXGH3f3SdmPgi4yyPUbdnd/BzjYhF5EJEf1vGefY2ZdZrbUzEY1rCMRyUWtYX8GmABMAvYCj6YeaGazzaxkZqWenp7Uw0QkZzWF3d33u/shd/8FWAJM7eOxne5edPdioVCotU8RqVNNYTez9l53ZwLbGtOOiOSlmlNvK4DpwBgz2w08AEw3s0mAA93AnTn2KA0wYcKEZO2FF15I1m677bZkbfny5QOuff/998llbr755mStvb09WZPq9Bt2d7+hwvDzOfQiIjnSJ+hEglDYRYJQ2EWCUNhFglDYRYLQhJPCzJkzk7WzzjorWZs3b16ylpqo8r777ksus2vXrmRt4cKFydq4ceOSNfkr7dlFglDYRYJQ2EWCUNhFglDYRYJQ2EWC0Kk36dN5552XrK1cuTJZW7duXcXxW2+9NbnMs88+m6x98sknydr69euTNfkr7dlFglDYRYJQ2EWCUNhFglDYRYIwd2/ayorFopdKpaatTwaf4447Lln76aefkrVhw4Yla2+88UayNn369Kr6+rUoFouUSqWK19HSnl0kCIVdJAiFXSQIhV0kCIVdJAiFXSSIai7/NB5YDoylfLmnTnd/wsxGA68AHZQvAXW9u3+VX6vSCl1dXcnaqlWrkrXNmzdXHO/r9FpfJk6cmKxdcsklNT1nNNXs2X8G5rn7ROBC4C4zmwgsAN5y97OBt7L7IjJI9Rt2d9/r7u9lt78DdgDjgBnAsuxhy4Dr8mpSROo3oPfsZtYBTAY2AWPdfW9W2kf5Zb6IDFJVh93MTgJeBe5x929717z8mduKn7s1s9lmVjKzUk9PT13Nikjtqgq7mQ2jHPQX3X11NrzfzNqzejtwoNKy7t7p7kV3LxYKhUb0LCI16DfsZmaUr8e+w90f61VaC9yS3b4FeK3x7YlIo1QzB91FwE3Ah2a2NRu7H3gIWGlmtwO7gOvzaVEaYefOncnaU089laytXr06Wdu3b19dPR3t2GPT/x3b29uTtWOO0cdFqtFv2N19I1DxK3PA7xrbjojkRX8SRYJQ2EWCUNhFglDYRYJQ2EWC0OWfhqC+Tnm99NJLFccXL16cXKa7u7velqp2wQUXJGsLFy5M1q699to82glFe3aRIBR2kSAUdpEgFHaRIBR2kSAUdpEgdOqthfbv35+sbd++PVmbM2dOsvbxxx/X1dNATJs2LVm79957K47PmDEjuYy+vZYvbV2RIBR2kSAUdpEgFHaRIBR2kSB0NL4BDh48mKzdeeedydrWrVuTtc8++6yungbioosuStbmzZuXrF155ZXJ2gknnFBXT9J42rOLBKGwiwShsIsEobCLBKGwiwShsIsE0e+pNzMbDyynfElmBzrd/QkzWwTcARy+NOv97v56Xo02y6ZNm5K1hx9+uOL45s2bk8vs3r277p4G4sQTT6w4Pnfu3OQyfc39NmLEiLp7ksGhmvPsPwPz3P09MxsJbDGz9VntcXf/9/zaE5FGqeZab3uBvdnt78xsBzAu78ZEpLEG9J7dzDqAycDh17pzzKzLzJaa2agG9yYiDVR12M3sJOBV4B53/xZ4BpgATKK85380sdxsMyuZWamnp6fSQ0SkCaoKu5kNoxz0F919NYC773f3Q+7+C7AEmFppWXfvdPeiuxcLhUKj+haRAeo37GZmwPPADnd/rNd4e6+HzQS2Nb49EWmUao7GXwTcBHxoZoe/pnU/cIOZTaJ8Oq4bSH+9awhZs2ZNTbVaTJw4MVm75pprkrW2trZkbf78+RXHTz311Oobk1+lao7GbwSsQmnIn1MXiUSfoBMJQmEXCUJhFwlCYRcJQmEXCcLcvWkrKxaLXiqVmrY+kWiKxSKlUqnS2TPt2UWiUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCqOZab8eb2Z/N7AMz225m/5aN/8bMNpnZp2b2ipkNz79dEalVNXv2/wMud/fzKV+e+SozuxD4I/C4u58FfAXcnl+bIlKvfsPuZf+b3R2W/ThwObAqG18GXJdLhyLSENVen70tu4LrAWA98Bnwtbv/nD1kNzAunxZFpBGqCru7H3L3ScDpwFTg76pdgZnNNrOSmZV6enpqbFNE6jWgo/Hu/jWwAfgH4FQzO3zJ59OBPYllOt296O7FQqFQV7MiUrtqjsYXzOzU7PYJwO+BHZRD/0/Zw24BXsurSRGp37H9P4R2YJmZtVH+47DS3f/LzD4CXjazB4H3gedz7FNE6tRv2N29C5hcYfxzyu/fRWQI0CfoRIJQ2EWCUNhFglDYRYJQ2EWCMHdv3srMeoBd2d0xwJdNW3ma+jiS+jjSUOvjTHev+Om1pob9iBWbldy92JKVqw/1EbAPvYwXCUJhFwmilWHvbOG6e1MfR1IfR/rV9NGy9+wi0lx6GS8SREvCbmZXmdnObLLKBa3oIeuj28w+NLOtZlZq4nqXmtkBM9vWa2y0ma03s0+y36Na1MciM9uTbZOtZnZ1E/oYb2YbzOyjbFLTf8nGm7pN+uijqdskt0le3b2pP0Ab5WmtfgsMBz4AJja7j6yXbmBMC9Z7CTAF2NZr7GFgQXZ7AfDHFvWxCJjf5O3RDkzJbo8E/geY2Oxt0kcfTd0mgAEnZbeHAZuAC4GVwKxs/FngnwfyvK3Ys08FPnX3z939R+BlYEYL+mgZd38HOHjU8AzKE3dCkybwTPTRdO6+193fy25/R3lylHE0eZv00UdTeVnDJ3ltRdjHAX/pdb+Vk1U68Ccz22Jms1vUw2Fj3X1vdnsfMLaFvcwxs67sZX7ubyd6M7MOyvMnbKKF2+SoPqDJ2ySPSV6jH6C72N2nAP8I3GVml7S6ISj/Zaf8h6gVngEmUL5GwF7g0Wat2MxOAl4F7nH3b3vXmrlNKvTR9G3idUzymtKKsO8Bxve6n5ysMm/uvif7fQBYQ2tn3tlvZu0A2e8DrWjC3fdn/9F+AZbQpG1iZsMoB+xFd1+dDTd9m1Tqo1XbJFv3gCd5TWlF2DcDZ2dHFocDs4C1zW7CzEaY2cjDt4ErgG19L5WrtZQn7oQWTuB5OFyZmTRhm5iZUZ7DcIe7P9ar1NRtkuqj2dskt0lem3WE8aijjVdTPtL5GbCwRT38lvKZgA+A7c3sA1hB+eXgT5Tfe90O/A3wFvAJ8CYwukV9/AfwIdBFOWztTejjYsov0buArdnP1c3eJn300dRtAvw95Ulcuyj/YfnXXv9n/wx8CvwncNxAnlefoBMJIvoBOpEwFHaRIBR2kSAUdpEgFHaRIBR2kSAUdpEgFHaRIP4fM1P6z1+fNGAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image_features in parsed_dataset.take(1):\n",
    "    plt.imshow(tf.squeeze(image_features['img'], axis=-1), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN layer の作成\n",
    "Glow に従ったNN Layerを作成する。公式のコードの https://github.com/openai/glow/blob/master/model.py#L420-L426 がおおよそこれに該当する。    \n",
    "※ log_s, t の計算部分が本家とはやや異なっている点に注意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"nn_test\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 16, 16, 2)]       0         \n",
      "_________________________________________________________________\n",
      "nn (NN)                      ((None, 16, 16, 2), (None 81924     \n",
      "=================================================================\n",
      "Total params: 81,924\n",
      "Trainable params: 80,900\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Layer, BatchNormalization, ReLU, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "class NN(Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape,\n",
    "        n_hidden=[512, 512],\n",
    "        kernel_size=[[3, 3], [1, 1]],\n",
    "        strides=[[1, 1], [1, 1]],\n",
    "        activation=\"relu\",\n",
    "        name=\"nn\",\n",
    "    ):\n",
    "        super(NN, self).__init__(name=\"nn\")\n",
    "        layer_list = []\n",
    "        for i, (hidden, kernel, stride) in enumerate(\n",
    "            zip(n_hidden, kernel_size, strides)\n",
    "        ):\n",
    "            layer_list.append(\n",
    "                Conv2D(\n",
    "                    hidden,\n",
    "                    kernel_size=kernel,\n",
    "                    strides=stride,\n",
    "                    activation=activation,\n",
    "                    padding='SAME',\n",
    "                    name=\"dense_{}_1\".format(i),\n",
    "                )\n",
    "            )\n",
    "            # In Glow,\n",
    "            # layers.append Actnorm not BatchNormalization\n",
    "            layer_list.append(BatchNormalization(trainable=True))\n",
    "        self.layer_list = layer_list\n",
    "        self.log_s_layer = Conv2D(\n",
    "            input_shape,\n",
    "            kernel_size=[3, 3],\n",
    "            strides=[1, 1],\n",
    "            padding='SAME',\n",
    "            kernel_initializer=\"zeros\",\n",
    "            activation=\"tanh\",\n",
    "            name=\"log_s\",\n",
    "        )\n",
    "        self.t_layer = Conv2D(\n",
    "            input_shape,\n",
    "            kernel_size=[3, 3],\n",
    "            strides=[1, 1],\n",
    "            padding='SAME',\n",
    "            kernel_initializer=\"zeros\",\n",
    "            name=\"t\",\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        y = x\n",
    "        for layer in self.layer_list:\n",
    "            y = layer(y)\n",
    "        log_s = self.log_s_layer(y)\n",
    "        t = self.t_layer(y)\n",
    "        return log_s, t\n",
    "\n",
    "\n",
    "def nn_test():\n",
    "    nn = NN(2, [256, 256])\n",
    "    x = tf.keras.Input([16, 16, 2])\n",
    "    log_s, t = nn(x)\n",
    "    # Non trainable params: -> Batch Normalization's params\n",
    "    tf.keras.Model(x, [log_s, t], name=\"nn_test\").summary()\n",
    "\n",
    "\n",
    "nn_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0022326293, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "nn = NN(2, [256, 256])\n",
    "x = tf.random.normal([100, 16, 16, 2])\n",
    "with tf.GradientTape() as t:\n",
    "    t.watch(x)\n",
    "    y = nn(x)\n",
    "    loss = - tf.reduce_mean(y - x)\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.0001) \n",
    "grads = t.gradient(loss, nn.trainable_variables)\n",
    "optimizer.apply_gradients(zip(grads, nn.trainable_variables))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RealNVP の Layer 作成\n",
    "同様に Glow の実装に従って作成する。公式のコードの https://github.com/openai/glow/blob/master/model.py#L367-L383 がおおよそこれに該当する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable_variables : 12\n",
      "Model: \"realnvp_test\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 16, 16, 4)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_split_1 (TensorFlow [(None, 16, 16, 2),  0           input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "nn (Model)                      [(None, 16, 16, 2),  81924       tf_op_layer_split_1[0][1]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Exp_1 (TensorFlowOp [(None, 16, 16, 2)]  0           nn[1][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_1 (TensorFlowOp [(None, 16, 16, 2)]  0           tf_op_layer_Exp_1[0][0]          \n",
      "                                                                 tf_op_layer_split_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_1 (TensorFlowOp [(None, 16, 16, 2)]  0           tf_op_layer_mul_1[0][0]          \n",
      "                                                                 nn[1][1]                         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_1 (TensorFlo [(None, 16, 16, 4)]  0           tf_op_layer_add_1[0][0]          \n",
      "                                                                 tf_op_layer_split_1[0][1]        \n",
      "==================================================================================================\n",
      "Total params: 81,924\n",
      "Trainable params: 80,900\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class RealNVP(tfb.Bijector):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape,\n",
    "        # this bijector do Tensor wise quantities. (I don't understand well...)\n",
    "        forward_min_event_ndims=3,\n",
    "        validate_args: bool = False,\n",
    "        name=\"real_nvp\",\n",
    "        n_hidden=[512, 512],  \n",
    "        **kargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_shape: \n",
    "                input_shape, \n",
    "                ex. [28, 28, 3] (image) [2] (x-y vector)\n",
    "            forward_min_event_ndims:\n",
    "                this bijector do \n",
    "                1. element-wize quantities => 0\n",
    "                2. vector-wize quantities => 1\n",
    "                3. matrix-wize quantities => 2\n",
    "                4. tensor-wize quantities => 3\n",
    "            n_hidden:\n",
    "                see. class NN\n",
    "            **kargs:\n",
    "                see. class NN\n",
    "                you can inuput NN's layers parameter here.\n",
    "        \"\"\"\n",
    "        super(RealNVP, self).__init__(\n",
    "            validate_args=validate_args, forward_min_event_ndims=forward_min_event_ndims, name=name\n",
    "        )\n",
    "\n",
    "        assert input_shape[-1] % 2 == 0\n",
    "        self.input_shape = input_shape\n",
    "        nn_layer = NN(input_shape[-1] // 2, n_hidden)\n",
    "        nn_input_shape = input_shape.copy()\n",
    "        nn_input_shape[-1] = input_shape[-1] // 2\n",
    "        x = tf.keras.Input(nn_input_shape)\n",
    "        log_s, t = nn_layer(x)\n",
    "        self.nn = Model(x, [log_s, t], name=\"nn\")\n",
    "\n",
    "    def _forward(self, x):\n",
    "        x_a, x_b = tf.split(x, 2, axis=-1)\n",
    "        y_b = x_b\n",
    "        log_s, t = self.nn(x_b)\n",
    "        s = tf.exp(log_s)\n",
    "        y_a = s * x_a + t\n",
    "        y = tf.concat([y_a, y_b], axis=-1)\n",
    "        return y\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        y_a, y_b = tf.split(y, 2, axis=-1)\n",
    "        x_b = y_b\n",
    "        log_s, t = self.nn(y_b)\n",
    "        s = tf.exp(log_s)\n",
    "        x_a = (y_a - t) / s\n",
    "        x = tf.concat([x_a, x_b], axis=-1)\n",
    "        return x\n",
    "\n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        _, x_b = tf.split(x, 2, axis=-1)\n",
    "        log_s, t = self.nn(x_b)\n",
    "        return log_s\n",
    "\n",
    "\n",
    "def realnvp_test():\n",
    "    realnvp = RealNVP(input_shape=[16, 16, 4], n_hidden=[256, 256])\n",
    "    x = tf.keras.Input([16, 16, 4])\n",
    "    y = realnvp.forward(x)\n",
    "    print('trainable_variables :', len(realnvp.trainable_variables))\n",
    "    Model(x, y, name=\"realnvp_test\").summary()\n",
    "\n",
    "\n",
    "realnvp_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeeze の Layer の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 32, 3]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[32, 32, 3][-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Layer の作成\n",
    "Split Layer では、channel 方向にデータを二分割して、片方を L 方向のループへ渡し、もう片方を $z_i$ とする。\n",
    "\n",
    "これは既存の tensorflow probability の Blockwise bijector を用いることで代用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           [(None, 16, 16, 4)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_split_5 (TensorFlow [(None, 16, 16, 2),  0           input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Exp_4 (TensorFlowOp [(None, 16, 16, 2)]  0           tf_op_layer_split_5[0][1]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_4 (TensorFlo [(None, 16, 16, 4)]  0           tf_op_layer_split_5[0][0]        \n",
      "                                                                 tf_op_layer_Exp_4[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 例\n",
    "blockwise =tfb.Blockwise(\n",
    "    bijectors=[tfb.Identity(), tfb.Exp()], block_sizes=[2, 2]\n",
    ")\n",
    "\n",
    "\n",
    "x = tf.keras.Input([16, 16, 4])\n",
    "y = blockwise.forward(x)\n",
    "\n",
    "tf.keras.Model(x, y).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TransformedDistribution の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_realnvp = 4\n",
    "bijector_chain = []\n",
    "for i in range(num_realnvp):\n",
    "    bijector_chain.append(RealNVP(input_shape=[32], n_hidden=[256, 256]))\n",
    "    bijector_chain.append(tfp.bijectors.Permute([1, 0]))\n",
    "\n",
    "flow = tfd.TransformedDistribution(\n",
    "    distribution=mvn,\n",
    "    bijector=tfb.Chain(list(reversed(bijector_chain)))\n",
    ")\n",
    "print('trainable_variables: ', len(flow.bijector.trainable_variables))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
