{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST X RealNVP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2変量正規分布 $\\leftrightarrow$ MNIST\n",
    "\n",
    "| |データサイズ|\n",
    "|----| ----|\n",
    "| 2変量標準正規分布 | 2|    \n",
    "|MNIST | 28 x 28 x 1 |\n",
    "|CIFER10| h x w x 3|\n",
    "| Text | Seq_len x Embedding_size ? |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RealNVP (Multi-Scale Architechture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Scale Architecture\n",
    "![](./multi-scale-arch.jpeg)\n",
    "\n",
    "効率的に変数変換を行うための機構として、RealNVPでは上のような機構を提案している。    \n",
    "これによってFlow-base Modelの形式を崩すことなく、計算量を抑えることができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squeezing\n",
    "![](squeezing.jpeg)\n",
    "\n",
    "入力を $h * w * c$ としたときに、その次元数を $\\cfrac{h}{2} * \\cfrac{w}{2} * 4c$ とする手法\n",
    "\n",
    "すると、RealNVP のカップリングレイヤー上で、    \n",
    "黒い部分が $x_a$ 白い部分が $x_b$ の役割を果たすようになる。\n",
    "\n",
    "図では平面だが、3次元テンソルの場合も上から眺めることで、同様の平面として処理している。\n",
    "\n",
    "\n",
    "※ $1 * 1 * c'$ 以降に変換を重ねたい場合の処理についてはおそらく未定義 (RealNVPの論文を読む限り)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題設定\n",
    "多変量標準正規分布 $\\leftrightarrow$ MNIST データセットの分布変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow を用いて解く\n",
    "\n",
    "## 方針\n",
    "0. 前準備\n",
    "1. データセットを作る\n",
    "2. Single-Scale Model を作る\n",
    "    1. RealNVP Bijector\n",
    "    2. BatchNormalization Bijector\n",
    "    3. Permutation Bijector\n",
    "    3. Squeeze Bijector\n",
    "    4. Single-Scale Model\n",
    "3. Multi-Scale Model を作る\n",
    "    1. Blockwise Bijector\n",
    "    2. Multi-Scale Model\n",
    "4. モデルの作成\n",
    "    1. TransformDistribution\n",
    "    2. Loss, Optimizar\n",
    "    3. Training\n",
    "    4. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow:  2.0.0-rc0\n",
      "tensorflow-probability:  0.8.0-rc0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "print('tensorflow: ', tf.__version__)\n",
    "print('tensorflow-probability: ', tfp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットを作る "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目標分布を作る\n",
    "今回は正規分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow             : shape: (2, 2, 256) mean: -0.003018 sd: 1.009833\n",
      "Tensorflow Probability : shape: (2, 2, 256) mean: -0.042071 sd: 0.980123\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow の distribution を使う場合\n",
    "z = tf.random.normal([2, 2, 256])\n",
    "print('Tensorflow             : shape: {} mean: {:.6f} sd: {:.6f}'.format(z.shape, tf.math.reduce_mean(z), tf.math.reduce_std(z)))\n",
    "# Tensorflow Probability の distribution を使う場合\n",
    "target_dist = tfd.Normal(loc=0., scale=1.)\n",
    "z = target_dist.sample([2, 2, 256])\n",
    "print('Tensorflow Probability : shape: {} mean: {:.6f} sd: {:.6f}'.format(z.shape, tf.math.reduce_mean(z), tf.math.reduce_std(z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 元分布(MNIST) データセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# From tensorflow's BEGINNER TUTORIALS\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.tobytes()]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def _preprocess(x):\n",
    "    x = tf.pad(x, paddings=[[0, 0], [2, 2], [2, 2]], mode=\"CONSTANT\")\n",
    "    x = tf.expand_dims(x, axis=-1)\n",
    "    return x\n",
    "\n",
    "def create_mnist():\n",
    "    (train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data()\n",
    "    print('train_dataset: {} images'.format(train_x.shape[0]))\n",
    "    print('test_dataset : {} images'.format(test_x.shape[0]))\n",
    "    if not os.path.exists(\"mnists\"):\n",
    "        os.mkdir(\"mnists\")\n",
    "\n",
    "    def _serialize_example_pyfunction(img, label):\n",
    "        feature = {\n",
    "            \"img\": _bytes_feature(img.numpy()),\n",
    "            \"label\": _int64_feature(label.numpy()),\n",
    "        }\n",
    "        example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        return example_proto.SerializeToString()\n",
    "    \n",
    "    @tf.function\n",
    "    def _gen_tf_serialize_example(img, label):\n",
    "        tf_string = tf.py_function(\n",
    "            _serialize_example_pyfunction, (img, label), tf.string\n",
    "        )\n",
    "        return tf.reshape(tf_string, ())\n",
    "\n",
    "    def _save_features_dataset(save_to, feature_dataset):\n",
    "        serialized_feature_dataset = train_features_dataset.map(\n",
    "            _gen_tf_serialize_example\n",
    "        )\n",
    "        writer = tf.data.experimental.TFRecordWriter(save_to)\n",
    "        writer.write(serialized_feature_dataset)\n",
    "\n",
    "    train_x = _preprocess(train_x)\n",
    "    train_features_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "    _save_features_dataset(os.path.join('mnists', 'train.tfrecord'), train_features_dataset)\n",
    "    \n",
    "    test_x = _preprocess(test_x)\n",
    "    test_features_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
    "    _save_features_dataset(os.path.join('mnists', 'test.tfrecord'), test_features_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: 60000 images\n",
      "test_dataset : 10000 images\n"
     ]
    }
   ],
   "source": [
    "create_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データセットの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description  = {\n",
    "    'img': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64, default_value=0)\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    feature = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    img = tf.io.decode_raw(feature['img'], out_type=tf.uint8)\n",
    "    img = tf.reshape(img, [32, 32, 1])\n",
    "    img = tf.cast(img, dtype=tf.float32)\n",
    "    img = (img / (255.0 / 2)) - 1\n",
    "    feature['img'] = img\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TFRecordDatasetV2 shapes: (), types: tf.string>\n",
      "<MapDataset shapes: {img: (32, 32, 1), label: ()}, types: {img: tf.float32, label: tf.int64}>\n"
     ]
    }
   ],
   "source": [
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "filenames = [os.path.join('mnists', 'train.tfrecord')]\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "print(raw_dataset)\n",
    "parsed_dataset = raw_dataset.map(_parse_function) \n",
    "print(parsed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image_features in parsed_dataset.take(1):\n",
    "    plt.imshow(tf.squeeze(image_features['img'], axis=-1), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-Scale Model を作る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RealNVP Layer\n",
    "\n",
    "Formula\n",
    "1. forward function\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "x_a, x_b &=& split(x) \\\\\n",
    "(\\log{s}, t) &=& NN(x_b) \\\\\n",
    "s &=& exp(\\log{s}) \\\\\n",
    "y_a &=& s \\odot x_a + t \\\\\n",
    "y_b &=& x_b \\\\\n",
    "y &=& concat(y_a, y_b)\n",
    "\\end{eqnarray*}\n",
    "\n",
    "2. reverse function\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "y_a, y_b &=& split(y)\\\\\n",
    "(\\log{s}, t) &=& NN(y_b)\\\\\n",
    "s &=& exp(\\log{s})\\\\\n",
    "x_a&=& (y_a - t) / s\\\\\n",
    "x_b &=& y_b\\\\\n",
    "x &=&  concat(x_a, x_b)\n",
    "\\end{eqnarray*}\n",
    "\n",
    "3. log-determinant\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "sum(\\log{|s|})\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN Layer\n",
    "ref. https://github.com/openai/glow/blob/master/model.py#L420-L426 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"nn_test\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 16, 16, 2)]       0         \n",
      "_________________________________________________________________\n",
      "nn_2 (NN)                    ((None, 16, 16, 2), (None 79876     \n",
      "=================================================================\n",
      "Total params: 79,876\n",
      "Trainable params: 79,876\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Layer, BatchNormalization, ReLU, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "class NN(Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape,\n",
    "        n_hidden=[512, 512],\n",
    "        kernel_size=[[3, 3], [1, 1]],\n",
    "        strides=[[1, 1], [1, 1]],\n",
    "        activation=\"relu\",\n",
    "        name=None,\n",
    "    ):\n",
    "        if name:\n",
    "            super(NN, self).__init__(name=name)\n",
    "        else:\n",
    "            super(NN, self).__init__()\n",
    "        layer_list = []\n",
    "        for i, (hidden, kernel, stride) in enumerate(\n",
    "            zip(n_hidden, kernel_size, strides)\n",
    "        ):\n",
    "            layer_list.append(\n",
    "                Conv2D(\n",
    "                    hidden,\n",
    "                    kernel_size=kernel,\n",
    "                    strides=stride,\n",
    "                    activation=activation,\n",
    "                    padding='SAME',\n",
    "                    name=\"dense_{}_1\".format(i),\n",
    "                )\n",
    "            )\n",
    "        self.layer_list = layer_list\n",
    "        self.log_s_layer = Conv2D(\n",
    "            input_shape,\n",
    "            kernel_size=[3, 3],\n",
    "            strides=[1, 1],\n",
    "            padding='SAME',\n",
    "            kernel_initializer=\"zeros\",\n",
    "            activation=\"tanh\",\n",
    "            name=\"log_s\",\n",
    "        )\n",
    "        self.t_layer = Conv2D(\n",
    "            input_shape,\n",
    "            kernel_size=[3, 3],\n",
    "            strides=[1, 1],\n",
    "            padding='SAME',\n",
    "            kernel_initializer=\"zeros\",\n",
    "            name=\"t\",\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        y = x\n",
    "        for layer in self.layer_list:\n",
    "            y = layer(y)\n",
    "        log_s = self.log_s_layer(y)\n",
    "        t = self.t_layer(y)\n",
    "        return log_s, t\n",
    "\n",
    "\n",
    "def nn_test():\n",
    "    nn = NN(2, [256, 256])\n",
    "    x = tf.keras.Input([16, 16, 2])\n",
    "    log_s, t = nn(x)\n",
    "    # Non trainable params: -> Batch Normalization's params\n",
    "    tf.keras.Model(x, [log_s, t], name=\"nn_test\").summary()\n",
    "\n",
    "\n",
    "nn_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RealNVP Bijector\n",
    "ref. https://github.com/openai/glow/blob/master/model.py#L367-L383"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable_variables : 8\n",
      "(64, 16, 16, 4) (64, 16, 16, 4) (64,)\n"
     ]
    }
   ],
   "source": [
    "class RealNVP(tfb.Bijector):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape,\n",
    "        # ??? this bijector do Tensor wise quantities. (I don't understand well...)\n",
    "        forward_min_event_ndims=3,\n",
    "        validate_args: bool = False,\n",
    "        name=\"real_nvp\",\n",
    "        n_hidden=[512, 512],\n",
    "        **kargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_shape: \n",
    "                input_shape, \n",
    "                ex. [28, 28, 3] (image) [2] (x-y vector)\n",
    "            forward_min_event_ndims:\n",
    "                this bijector do \n",
    "                1. element-wize quantities => 0\n",
    "                2. vector-wize quantities => 1\n",
    "                3. matrix-wize quantities => 2\n",
    "                4. tensor-wize quantities => 3\n",
    "            n_hidden:\n",
    "                see. class NN\n",
    "            **kargs:\n",
    "                see. class NN\n",
    "                you can inuput NN's layers parameter here.\n",
    "        \"\"\"\n",
    "        super(RealNVP, self).__init__(\n",
    "            validate_args=validate_args,\n",
    "            forward_min_event_ndims=forward_min_event_ndims,\n",
    "            name=name,\n",
    "        )\n",
    "\n",
    "        assert input_shape[-1] % 2 == 0\n",
    "        self.input_shape = input_shape\n",
    "        nn_layer = NN(input_shape[-1] // 2, n_hidden)\n",
    "        nn_input_shape = input_shape.copy()\n",
    "        nn_input_shape[-1] = input_shape[-1] // 2\n",
    "        x = tf.keras.Input(nn_input_shape)\n",
    "        log_s, t = nn_layer(x)\n",
    "        self.nn = Model(x, [log_s, t], name=self.name + \"/nn\")\n",
    "\n",
    "    def _forward(self, x):\n",
    "        x_a, x_b = tf.split(x, 2, axis=-1)\n",
    "        y_b = x_b\n",
    "        log_s, t = self.nn(x_b)\n",
    "        s = tf.exp(log_s)\n",
    "        y_a = s * x_a + t\n",
    "        y = tf.concat([y_a, y_b], axis=-1)\n",
    "        return y\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        y_a, y_b = tf.split(y, 2, axis=-1)\n",
    "        x_b = y_b\n",
    "        log_s, t = self.nn(y_b)\n",
    "        s = tf.exp(log_s)\n",
    "        x_a = (y_a - t) / s\n",
    "        x = tf.concat([x_a, x_b], axis=-1)\n",
    "        return x\n",
    "\n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        _, x_b = tf.split(x, 2, axis=-1)\n",
    "        log_s, t = self.nn(x_b)\n",
    "        return tf.reduce_sum(log_s)\n",
    "\n",
    "\n",
    "def realnvp_test():\n",
    "    realnvp = RealNVP(input_shape=[16, 16, 4], n_hidden=[256, 256])\n",
    "    x = tf.keras.Input([16, 16, 4])\n",
    "    y = realnvp.forward(x)\n",
    "    print(\"trainable_variables :\", len(realnvp.trainable_variables))\n",
    "\n",
    "    flow = tfd.TransformedDistribution(\n",
    "        event_shape=[16, 16, 4],\n",
    "        distribution=tfd.Normal(loc=0.0, scale=1.0),\n",
    "        bijector=realnvp,\n",
    "    )\n",
    "    x = flow.sample(64)\n",
    "    y = realnvp.inverse(x)\n",
    "    log_prob = flow.log_prob(y)\n",
    "    print(\n",
    "        x.shape,\n",
    "        y.shape,\n",
    "        log_prob.shape,\n",
    "        # -tf.reduce_mean(log_prob),\n",
    "        # -tf.reduce_mean(flow.distribution.log_prob(x)),\n",
    "        # -tf.reduce_mean(\n",
    "        #     flow.bijector.forward_log_det_jacobian(\n",
    "        #         x, event_ndims=flow._maybe_get_static_event_ndims()\n",
    "        #     )\n",
    "        # ),\n",
    "        # -tf.reduce_mean(flow._log_prob(x)),\n",
    "        # flow._finish_log_prob_for_one_fiber(\n",
    "        #     y,\n",
    "        #     x,\n",
    "        #     flow.bijector.forward_log_det_jacobian(\n",
    "        #         x, event_ndims=flow._maybe_get_static_event_ndims()\n",
    "        #     ),\n",
    "        #     flow._maybe_get_static_event_ndims(),\n",
    "        #     \n",
    "        # ),\n",
    "        # tf.reduce_sum(flow.distribution.log_prob(flow._maybe_rotate_dims(x, rotate_right=True)), axis=flow._reduce_event_indices)\n",
    "    )\n",
    "\n",
    "\n",
    "realnvp_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BatchNormalization Layer\n",
    "\n",
    "ref. tensorflow_probability/bijector/BatchNormalization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation Bijector\n",
    "Channel 軸に反転を加える。    \n",
    "Glowではこれを Invertible 1x1 convolution に改良している。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-1.4058963, shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1866, shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RevPermute(tfb.Bijector):\n",
    "    def __init__(\n",
    "        self,\n",
    "        axis=[-1],\n",
    "        forward_min_event_ndims=0,\n",
    "        validate_args=False,\n",
    "        name=\"RevPermute\",\n",
    "    ):\n",
    "        super(RevPermute, self).__init__(\n",
    "            forward_min_event_ndims=forward_min_event_ndims,\n",
    "            validate_args=validate_args,\n",
    "            name=name,\n",
    "            is_constant_jacobian=True\n",
    "        )\n",
    "        self._axis = axis\n",
    "\n",
    "    @property\n",
    "    def axis(self):\n",
    "        return self._axis\n",
    "\n",
    "    def _forward(self, x):\n",
    "        return tf.reverse(x, self.axis)\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        return tf.reverse(y, self.axis)\n",
    "\n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        return tf.constant(0.0, dtype=x.dtype)\n",
    "\n",
    "    def _inverse_log_det_jacobian(self, y):\n",
    "        return tf.constant(0.0, dtype=y.dtype)\n",
    "\n",
    "\n",
    "def test_revPermute():\n",
    "    revPermute = RevPermute()\n",
    "    x = tf.keras.Input([16, 16, 4])\n",
    "    y = revPermute.forward(x)\n",
    "    # tf.keras.Model(x, y).summary()\n",
    "\n",
    "    x = tf.random.normal([2, 16, 16, 4])\n",
    "    y = revPermute.forward(x)\n",
    "    z = revPermute.inverse(y)\n",
    "    flow = tfd.TransformedDistribution(distribution=target_dist, bijector=revPermute)\n",
    "    print(tf.reduce_mean(flow.log_prob(tf.random.normal([2, 16, 16, 3]))))\n",
    "    return tf.reduce_sum(z - x)\n",
    "\n",
    "\n",
    "test_revPermute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeeze Bijector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "(64, 16, 16, 2) (64, 8, 8, 8) (64,)\n"
     ]
    }
   ],
   "source": [
    "class Squeeze3D(tfb.Bijector):\n",
    "    def __init__(\n",
    "        self,\n",
    "        factor=2,\n",
    "        forward_min_event_ndims=0,\n",
    "        inverse_min_event_ndims=0,\n",
    "        validate_args=False,\n",
    "        name=\"Squeeze\",\n",
    "    ):\n",
    "        self._factor = factor\n",
    "        super(Squeeze3D, self).__init__(\n",
    "            forward_min_event_ndims=forward_min_event_ndims,\n",
    "            inverse_min_event_ndims=inverse_min_event_ndims,\n",
    "            name=name,\n",
    "            is_constant_jacobian=True\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def factor(self):\n",
    "        return self._factor\n",
    "\n",
    "    def _forward(self, x):\n",
    "        (H, W, C) = x.shape[1:]\n",
    "        batch_size = tf.shape(x)[0:1]\n",
    "        tmp_shape = tf.concat(\n",
    "            [\n",
    "                batch_size,\n",
    "                (H // self.factor, self.factor, W // self.factor, self.factor, C),\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "        output_shape = tf.concat(\n",
    "            [batch_size, (H // self.factor, W // self.factor, C * self.factor ** 2)],\n",
    "            axis=0,\n",
    "        )\n",
    "        y = tf.reshape(x, tmp_shape)\n",
    "        y = tf.transpose(y, [0, 1, 3, 5, 2, 4])\n",
    "        y = tf.reshape(y, output_shape)\n",
    "        return y\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        (H, W, C) = y.shape[1:]\n",
    "        batch_size = tf.shape(y)[0:1]\n",
    "        tmp_shape = tf.concat(\n",
    "            [batch_size, (H, W, C // self.factor ** 2, self.factor, self.factor)], axis=0\n",
    "        )\n",
    "        output_shape = tf.concat(\n",
    "            [batch_size, (H * self.factor, W * self.factor, C // self.factor ** 2)], axis=0\n",
    "        )\n",
    "        x = tf.reshape(y, tmp_shape)\n",
    "        x = tf.transpose(x, [0, 1, 4, 2, 5, 3])\n",
    "        x = tf.reshape(x, output_shape)\n",
    "        return x\n",
    "\n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        return tf.constant(0.0, dtype=x.dtype)\n",
    "\n",
    "\n",
    "def test_squeeze3D():\n",
    "    factor = 2\n",
    "    x = tf.Variable([[[1, 2, 5, 6], [3, 4, 7, 8], [9, 10, 13, 14], [11, 12, 15, 16]]])\n",
    "    x = tf.expand_dims(x, axis=-1)\n",
    "    squeeze3d = Squeeze3D()\n",
    "    y = squeeze3d.forward(x)\n",
    "    z = squeeze3d.inverse(y)\n",
    "    print(tf.reduce_sum(x - z))\n",
    "    \n",
    "    flow = tfd.TransformedDistribution(\n",
    "        event_shape=[16, 16, 2],\n",
    "        distribution=tfd.Normal(loc=0., scale=1.),\n",
    "        bijector=squeeze3d\n",
    "    )\n",
    "    x = tf.random.normal([64, 16, 16, 2])\n",
    "    y = flow.bijector.forward(x)\n",
    "    log_prob = flow.log_prob(y)\n",
    "    print(x.shape, y.shape, log_prob.shape)\n",
    "    \n",
    "\n",
    "test_squeeze3D()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-Scale Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,) tf.Tensor(1450.8916, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def gen_flow_chain(level=3):\n",
    "    flow_chain_list = []\n",
    "    for i in range(level):\n",
    "        flow_chain_list.append(Squeeze3D())\n",
    "        flow_chain_list.append(tfb.BatchNormalization())\n",
    "        flow_chain_list.append(RevPermute()),\n",
    "        flow_chain_list.append(RealNVP(input_shape=[16, 16, 4], n_hidden=[256, 256])),\n",
    "        flow_chain_list.append(tfb.Invert(Squeeze3D()))\n",
    "    return tfb.Chain(list(reversed(flow_chain_list)))  \n",
    "    \n",
    "flow_bijector = gen_flow_chain()\n",
    "\n",
    "flow = tfd.TransformedDistribution(\n",
    "    event_shape=[32, 32, 1],\n",
    "    distribution=tfd.Normal(loc=0.0, scale=1.0),\n",
    "    bijector=tfb.Invert(flow_bijector),\n",
    ")\n",
    "\n",
    "x = tf.random.normal([64, 32, 32, 1])\n",
    "log_prob = flow.log_prob(x)\n",
    "print(log_prob.shape, -tf.reduce_mean(log_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Scale Model を作る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blockwise Bijector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3599, shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ref: https://github.com/tensorflow/probability/blob/master/tensorflow_probability/python/bijectors/blockwise.py\n",
    "# TODO: ask is the event_ndim for forward/invert_log_determinants correctly.\n",
    "class Blockwise3D(tfb.Bijector):\n",
    "    def __init__(self, bijectors, block_sizes=None, validate_args=False, name=None):\n",
    "        if not name:\n",
    "            name = \"blockwise3D_of_\" + \"_and_\".join([b.name for b in bijectors])\n",
    "            name = name.replace(\"/\", \"\")\n",
    "        super(Blockwise3D, self).__init__(\n",
    "            # ???\n",
    "            forward_min_event_ndims=3,\n",
    "            validate_args=validate_args,\n",
    "            name=name,\n",
    "        )\n",
    "        self._bijectors = bijectors\n",
    "        self._block_sizes = block_sizes\n",
    "\n",
    "    @property\n",
    "    def bijectors(self):\n",
    "        return self._bijectors\n",
    "\n",
    "    @property\n",
    "    def block_sizes(self):\n",
    "        return self._block_sizes\n",
    "\n",
    "    def _forward(self, x):\n",
    "        split_x = (\n",
    "            tf.split(x, len(self.bijectors), axis=-1)\n",
    "            if self.block_sizes is None\n",
    "            else tf.split(x, self.block_sizes, axis=-1)\n",
    "        )\n",
    "        split_y = [b.forward(x_) for b, x_ in zip(self.bijectors, split_x)]\n",
    "        y = tf.concat(split_y, axis=-1)\n",
    "        return y\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        split_y = (\n",
    "            tf.split(y, len(self.bijectors), axis=-1)\n",
    "            if self.block_sizes is None\n",
    "            else tf.split(y, self.block_sizes, axis=-1)\n",
    "        )\n",
    "        split_x = [b.inverse(y_) for b, y_ in zip(self.bijectors, split_y)]\n",
    "        x = tf.concat(split_x, axis=-1)\n",
    "        return x\n",
    "\n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        split_x = (\n",
    "            tf.split(x, len(self.bijectors), axis=-1)\n",
    "            if self.block_sizes is None\n",
    "            else tf.split(x, self.block_sizes, axis=-1)\n",
    "        )\n",
    "        fldjs = [\n",
    "            # ???\n",
    "            b.forward_log_det_jacobian(x_, event_ndims=3)\n",
    "            for b, x_ in zip(self.bijectors, split_x)\n",
    "        ]\n",
    "        return sum(fldjs)\n",
    "\n",
    "    def _inverse_log_det_jacobian(self, y):\n",
    "        split_y = (\n",
    "            tf.split(y, len(self.bijectors), axis=-1)\n",
    "            if self.block_sizes is None\n",
    "            else tf.split(y, self.block_sizes, axis=-1)\n",
    "        )\n",
    "        ildjs = [\n",
    "            b.inverse_log_det_jacobian(y_, event_ndims=3)\n",
    "            for b, y_ in zip(self.bijectors, split_y)\n",
    "        ]\n",
    "        return sum(ildjs)\n",
    "\n",
    "\n",
    "def test_blockwise3D():\n",
    "    blockwise3D = Blockwise3D(\n",
    "        bijectors=[\n",
    "            tfb.Identity(),\n",
    "            RealNVP(input_shape=[16, 16, 2], n_hidden=[256, 256]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    x = tf.keras.Input([16, 16, 4])\n",
    "    y = blockwise3D.forward(x)\n",
    "    # tf.keras.Model(x, y).summary()\n",
    "\n",
    "    x = tf.random.normal([3, 16, 16, 4])\n",
    "    y = blockwise3D.forward(x)\n",
    "    z = blockwise3D.inverse(y)\n",
    "    return tf.reduce_sum(z - x)\n",
    "\n",
    "\n",
    "test_blockwise3D()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Scale Model\n",
    "簡単のために、次のようなモデルを用いる。\n",
    "0. Squeeze $[32, 32, 1] \\rightarrow [16, 16, 4]$ \n",
    "1. Flow-step\n",
    "2. if not last Flow-step    \n",
    "    BlockWise3D \n",
    "        1. Identity\n",
    "        2. 0 へ\n",
    "3. Unsqueeze $[16, 16, 4] \\rightarrow [32, 32, 1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "試しに、L=3の場合の次元数の遷移を示す。    \n",
    "下のコードでは、RealNVP のモデル図を png ファイルとして書き出している。\n",
    "\n",
    "![](./multi-scale-arch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4152, shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_flowSteps(\n",
    "    # for realnvp\n",
    "    input_shape: list,\n",
    "    n_hidden: list = [256, 256],\n",
    "    # for flowStep\n",
    "    k=2,\n",
    "    forward_min_event_ndims: int = 3,\n",
    "    validate_args: bool = False,\n",
    "    name: str = \"flow_step\",\n",
    "):\n",
    "    flow_step_list = []\n",
    "    for i in range(k):\n",
    "        flow_step_list.append(tfb.BatchNormalization(validate_args=validate_args))\n",
    "        flow_step_list.append(RevPermute(validate_args=validate_args)),\n",
    "        flow_step_list.append(\n",
    "            RealNVP(\n",
    "                input_shape=input_shape,\n",
    "                n_hidden=n_hidden,\n",
    "                validate_args=validate_args,\n",
    "                name=\"{}_{}/realnvp\".format(name, i),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    flowSteps = tfb.Chain(\n",
    "        list(reversed(flow_step_list)), validate_args=validate_args, name=name\n",
    "    )\n",
    "    return flowSteps\n",
    "\n",
    "\n",
    "def test_gen_flowSteps():\n",
    "    flowSteps = gen_flowSteps(\n",
    "        k=2, input_shape=[16, 16, 4], forward_min_event_ndims=0, name=\"flowstep_0\"\n",
    "    )\n",
    "    x = tf.keras.Input([16, 16, 4])\n",
    "    y = flowSteps(x)\n",
    "    # tf.keras.Model(x, y).summary()\n",
    "\n",
    "    x = tf.random.normal([6, 16, 16, 4])\n",
    "    y = flowSteps.forward(x)\n",
    "    z = flowSteps.inverse(y)\n",
    "    return tf.reduce_sum(z - x)\n",
    "\n",
    "\n",
    "test_gen_flowSteps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=6300, shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_flow(input_shape, level=3, flow_step_args: dict = None):\n",
    "    def _gen_input_shapes(input_shape, level):\n",
    "        input_shape = input_shape\n",
    "        input_shapes = []\n",
    "        for i in range(level):\n",
    "            input_shape = [\n",
    "                input_shape[0] // 2,\n",
    "                input_shape[1] // 2,\n",
    "                input_shape[2] * 4 - i * 8,\n",
    "            ]\n",
    "            input_shapes.append(input_shape)\n",
    "        return input_shapes\n",
    "\n",
    "    input_shapes = _gen_input_shapes(input_shape, level)\n",
    "\n",
    "    def _add_flow(_input_shapes, flow_step_args):\n",
    "        flow_lists = []\n",
    "        flow_lists.append(\n",
    "            Squeeze3D(name=\"Squeeze_{}\".format(level - len(_input_shapes)))\n",
    "        )\n",
    "        flowSteps = gen_flowSteps(\n",
    "           k=2,\n",
    "           input_shape=_input_shapes[0],\n",
    "           name=\"Flowsteps_{}\".format(level - len(_input_shapes)),\n",
    "        )\n",
    "        flow_lists.append(flowSteps)\n",
    "        if len(_input_shapes) != 1:\n",
    "            flow_lists.append(\n",
    "                Blockwise3D(\n",
    "                    [\n",
    "                        tfb.Identity(),\n",
    "                        tfb.Chain(\n",
    "                            list(reversed(_add_flow(_input_shapes[1:], flow_step_args)))\n",
    "                        ),\n",
    "                    ],\n",
    "                    name=\"Blockwise3D_{}\".format(level - len(_input_shapes)),\n",
    "                )\n",
    "            )\n",
    "        flow_lists.append(\n",
    "            tfb.Invert(\n",
    "                Squeeze3D(name=\"Unsqueeze_{}\".format(level - len(_input_shapes)))\n",
    "            )\n",
    "        )\n",
    "        return flow_lists\n",
    "\n",
    "    return tfb.Chain(list(reversed(_add_flow(input_shapes, level))))\n",
    "\n",
    "\n",
    "def test_gen_flow():\n",
    "    flow = gen_flow([32, 32, 1])\n",
    "    print(len(flow.trainable_variables))\n",
    "    x = tf.keras.Input([32, 32, 1])\n",
    "    y = flow.forward(x)\n",
    "    # tf.keras.Model(x, y).summary()\n",
    "    tf.keras.utils.plot_model(\n",
    "        tf.keras.Model(x, y), show_shapes=True, to_file=\"realnvp.png\"\n",
    "    )\n",
    "    x = tf.random.normal([3, 32, 32, 1])\n",
    "    y = flow.forward(x)\n",
    "    z = flow.inverse(y) \n",
    "    return tf.reduce_sum(z - x)\n",
    "\n",
    "test_gen_flow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TransformDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "trainable_variables:  48\n"
     ]
    }
   ],
   "source": [
    "flow_bijector = gen_flow([32, 32, 1])\n",
    "print(len(flow_bijector.trainable_variables))\n",
    "flow = tfd.TransformedDistribution(\n",
    "    event_shape =[32, 32, 1],\n",
    "    distribution=tfd.Normal(loc=0.0, scale=1.0),\n",
    "    bijector=flow_bijector\n",
    ")\n",
    "print('trainable_variables: ', len(flow.bijector.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss, Optimizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: 'checkpoints' を削除できません: そのようなファイルやディレクトリはありません\n"
     ]
    }
   ],
   "source": [
    "!rm -r checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def loss():\n",
    "    return - tf.reduce_mean(flow.log_prob(targets['img']))\n",
    "\n",
    "\n",
    "optimizer = tf.optimizers.Adam(learning_rate=1e-4) \n",
    "log = tf.summary.create_file_writer('checkpoints')\n",
    "avg_loss = tf.keras.metrics.Mean(name='loss', dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 32, 32, 1)\n",
      "WARNING:tensorflow:From /home/meguru/Github/tf-test/venv/lib/python3.7/site-packages/tensorflow_probability/python/bijectors/batch_normalization.py:207: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "tf.Tensor(797.7849, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=120\n",
    "train_dataset = parsed_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "for target in train_dataset.take(1):\n",
    "    targets = target\n",
    "print(targets['img'].shape)\n",
    "with tf.GradientTape() as tape:\n",
    "    log_prob_loss = loss()\n",
    "grads = tape.gradient(log_prob_loss, flow.trainable_variables)\n",
    "print(log_prob_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=1000> Loss -213421.187500\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=2000> Loss -213894.812500\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=3000> Loss -214341.640625\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=4000> Loss -214599.546875\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=5000> Loss -214744.656250\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=6000> Loss -214839.281250\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=7000> Loss -214908.000000\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=8000> Loss -214962.078125\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=9000> Loss -215007.265625\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=10000> Loss -215047.781250\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=11000> Loss -215083.937500\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=12000> Loss -215116.984375\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=13000> Loss -215148.953125\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=14000> Loss -215178.781250\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=15000> Loss -215207.593750\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "\n",
    "flag = False\n",
    "for epoch in range(n_epochs):\n",
    "    if flag:\n",
    "        print('raise NaN')\n",
    "        break\n",
    "    for targets in train_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            log_prob_loss = loss()\n",
    "        grads = tape.gradient(log_prob_loss, flow.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, flow.trainable_variables))\n",
    "        if tf.math.is_nan(log_prob_loss):\n",
    "            flag=True\n",
    "            break\n",
    "        avg_loss.update_state(log_prob_loss)\n",
    "        if tf.equal(optimizer.iterations % 1000, 0):\n",
    "            print(\"Step {} Loss {:.6f}\".format(optimizer.iterations, avg_loss.result()))\n",
    "        if tf.equal(optimizer.iterations % 100, 0):\n",
    "            with log.as_default():\n",
    "                tf.summary.scalar(\"loss\", avg_loss.result(), step=optimizer.iterations)\n",
    "                avg_loss.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [os.path.join('mnists', 'test.tfrecord')]\n",
    "test_raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "test_parsed_dataset = test_raw_dataset.map(_parse_function) \n",
    "test_dataset = test_parsed_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log probability:  -1.6098473\n",
      "inv mean:  1.9736588e-06  std:  1.1755073\n",
      "re:trg mean:  -0.80886143  std:  0.5384503\n",
      "(1, 32, 32, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3d8a5d04d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "for targets in test_dataset.take(1):\n",
    "    trg = targets[\"img\"]\n",
    "    inv = flow.bijector.inverse(trg)\n",
    "    re_trg = flow.bijector.forward(inv)\n",
    "\n",
    "print('log probability: ', tf.reduce_mean(tfd.Normal(0., 1.).log_prob(inv)).numpy())\n",
    "print(\"inv mean: \", tf.reduce_mean(inv).numpy(), \" std: \", tf.math.reduce_std(inv).numpy())\n",
    "print(\"re:trg mean: \", tf.reduce_mean(re_trg).numpy(), \" std: \", tf.math.reduce_std(re_trg).numpy())\n",
    "\n",
    "re_inv = np.array([(inv[0] + inv[1]) / 2.0])\n",
    "print(re_inv.shape)\n",
    "re_re_trg = flow.bijector.forward(re_inv)\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 1)\n",
    "ax.imshow(tf.squeeze(trg[0], axis=-1), aspect=\"auto\", cmap=\"gray_r\")\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 4)\n",
    "ax.imshow(tf.squeeze(re_trg[0], axis=-1), aspect=\"auto\", cmap=\"gray_r\")\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 2)\n",
    "ax.imshow(tf.squeeze(trg[1], axis=-1), aspect=\"auto\", cmap=\"gray_r\")\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 5)\n",
    "ax.imshow(tf.squeeze(re_trg[1], axis=-1), aspect=\"auto\", cmap=\"gray_r\")\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 3)\n",
    "ax.imshow(tf.squeeze(re_inv[0], axis=-1), aspect=\"auto\", cmap=\"gray_r\")\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 6)\n",
    "ax.imshow(tf.squeeze(re_re_trg[0], axis=-1), aspect=\"auto\", cmap=\"gray_r\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
