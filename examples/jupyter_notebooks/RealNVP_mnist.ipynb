{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZrwVQsM9TiUw"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Original code\n",
    "https://github.com/MokkeMeguru/glow-realnvp-tutorial/\n",
    "\n",
    "If you have any Problem, please let me(@MokkeMeguru) it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ltPJCG6pAUoc"
   },
   "source": [
    "# TFP Bijector: RealNVP x MNIST\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/RealNVP_mnist.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/RealNVP_mnist.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRVR-tGTR31S"
   },
   "source": [
    "In this example we show how to build a RealNVP using TFP's \"Bijector.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RealNVP x MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate normal distribution $\\rightarrow$ MNIST\n",
    "\n",
    "| | Data Dimention|\n",
    "|----| ----|\n",
    "| Multivariate normal distribution (2) | n(2)|    \n",
    "|MNIST | 28 x 28 x 1 |\n",
    "|CIFER10| h x w x 3|\n",
    "| Text | Seq_len x Embedding_size ? |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RealNVP (Multi-Scale Architechture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Scale Architecture\n",
    "![https://arxiv.org/abs/1410.8516](../img/multi-scale-arch.jpeg)\n",
    "\n",
    "RealNVP proposes above architecture for the efficient variable conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squeezing\n",
    "![https://arxiv.org/abs/1410.8516](../img/squeezing.jpeg)\n",
    "\n",
    "||Dimention|\n",
    "|---|---|\n",
    "| Input | $h * w * c$ |\n",
    "| Output | $\\cfrac{h}{2} * \\cfrac{w}{2} * 4c$ |\n",
    "\n",
    "In Coupling Layer (RealNVP Bijector), Black is to be $x_a$ , White is to be $x_b$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Setting\n",
    "Multivariate normal distiribution $\\leftrightarrow$ MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Tensorflow\n",
    "\n",
    "## Implementation Plan\n",
    "0. Preprocess\n",
    "1. Create Dataset\n",
    "2. Build Single-Scale Model\n",
    "    1. RealNVP Bijector\n",
    "    2. BatchNormalization Bijector\n",
    "    3. Permutation Bijector\n",
    "    3. Squeeze Bijector\n",
    "    4. Single-Scale Model\n",
    "3. Build Multi-Scale Model\n",
    "    1. Blockwise Bijector\n",
    "    2. Multi-Scale Model\n",
    "4. Build Model\n",
    "    1. TransformDistribution\n",
    "    2. Loss, Optimizar\n",
    "    3. Training\n",
    "    4. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow:  2.0.0-rc0\n",
      "tensorflow-probability:  0.8.0-rc0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "print('tensorflow: ', tf.__version__)\n",
    "print('tensorflow-probability: ', tfp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Target Distribution ($z$)\n",
    "In this part, use Multivariate normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow             : shape: (2, 2, 256) mean: 0.025585 sd: 1.034393\n",
      "Tensorflow Probability : shape: (2, 2, 256) mean: -0.011340 sd: 1.027189\n"
     ]
    }
   ],
   "source": [
    "# use Tensorflow's distribution\n",
    "z = tf.random.normal([2, 2, 256])\n",
    "print('Tensorflow             : shape: {} mean: {:.6f} sd: {:.6f}'.format(z.shape, tf.math.reduce_mean(z), tf.math.reduce_std(z)))\n",
    "# use Tensorflow Probability's distribution\n",
    "target_dist = tfd.Normal(loc=0., scale=1.)\n",
    "z = target_dist.sample([2, 2, 256])\n",
    "print('Tensorflow Probability : shape: {} mean: {:.6f} sd: {:.6f}'.format(z.shape, tf.math.reduce_mean(z), tf.math.reduce_std(z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Original Distribution (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: 60000 images\n",
      "test_dataset : 10000 images\n"
     ]
    }
   ],
   "source": [
    "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print('train_dataset: {} images'.format(len(train_x)))\n",
    "print('test_dataset : {} images'.format(len(test_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "@tf.function\n",
    "def _parse_function(img, label):\n",
    "    feature = {}\n",
    "    img = tf.pad(img, paddings=[[2, 2], [2, 2]], mode=\"CONSTANT\")\n",
    "    img = tf.expand_dims(img, axis=-1)\n",
    "    img = tf.reshape(img, [32, 32, 1])\n",
    "    img = tf.cast(img, dtype=tf.float32)\n",
    "    img = (img / (255.0 / 2)) - 1\n",
    "    feature['img'] = img\n",
    "    feature['label'] = label\n",
    "    return feature\n",
    "\n",
    "train_dataset_raw = tf.data.Dataset.from_tensor_slices((train_x, train_y)).map(_parse_function)\n",
    "test_dataset_raw = tf.data.Dataset.from_tensor_slices((test_x, test_y)).map(_parse_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image_features in train_dataset_raw.take(1):\n",
    "    plt.imshow(tf.squeeze(image_features['img'], axis=-1), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Single-Scale Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RealNVP Bijector\n",
    "\n",
    "Formula\n",
    "1. forward function\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "x_a, x_b &=& split(x) \\\\\n",
    "(\\log{s}, t) &=& NN(x_b) \\\\\n",
    "s &=& exp(\\log{s}) \\\\\n",
    "y_a &=& s \\odot x_a + t \\\\\n",
    "y_b &=& x_b \\\\\n",
    "y &=& concat(y_a, y_b)\n",
    "\\end{eqnarray*}\n",
    "\n",
    "2. reverse function\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "y_a, y_b &=& split(y)\\\\\n",
    "(\\log{s}, t) &=& NN(y_b)\\\\\n",
    "s &=& exp(\\log{s})\\\\\n",
    "x_a&=& (y_a - t) / s\\\\\n",
    "x_b &=& y_b\\\\\n",
    "x &=&  concat(x_a, x_b)\n",
    "\\end{eqnarray*}\n",
    "\n",
    "3. log-determinant\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "sum(\\log{|s|})\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN Layer\n",
    "ref. https://github.com/openai/glow/blob/master/model.py#L420-L426 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"nn_test\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 16, 16, 2)]       0         \n",
      "_________________________________________________________________\n",
      "nn (NN)                      ((None, 16, 16, 2), (None 79876     \n",
      "=================================================================\n",
      "Total params: 79,876\n",
      "Trainable params: 79,876\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Layer, BatchNormalization, ReLU, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "class NN(Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape,\n",
    "        n_hidden=[512, 512],\n",
    "        kernel_size=[[3, 3], [1, 1]],\n",
    "        strides=[[1, 1], [1, 1]],\n",
    "        activation=\"relu\",\n",
    "        name=None,\n",
    "    ):\n",
    "        if name:\n",
    "            super(NN, self).__init__(name=name)\n",
    "        else:\n",
    "            super(NN, self).__init__()\n",
    "        layer_list = []\n",
    "        for i, (hidden, kernel, stride) in enumerate(\n",
    "            zip(n_hidden, kernel_size, strides)\n",
    "        ):\n",
    "            layer_list.append(\n",
    "                Conv2D(\n",
    "                    hidden,\n",
    "                    kernel_size=kernel,\n",
    "                    strides=stride,\n",
    "                    activation=activation,\n",
    "                    padding='SAME',\n",
    "                    name=\"dense_{}_1\".format(i),\n",
    "                )\n",
    "            )\n",
    "        self.layer_list = layer_list\n",
    "        self.log_s_layer = Conv2D(\n",
    "            input_shape,\n",
    "            kernel_size=[3, 3],\n",
    "            strides=[1, 1],\n",
    "            padding='SAME',\n",
    "            kernel_initializer=\"zeros\",\n",
    "            activation=\"tanh\",\n",
    "            name=\"log_s\",\n",
    "        )\n",
    "        self.t_layer = Conv2D(\n",
    "            input_shape,\n",
    "            kernel_size=[3, 3],\n",
    "            strides=[1, 1],\n",
    "            padding='SAME',\n",
    "            kernel_initializer=\"zeros\",\n",
    "            name=\"t\",\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        y = x\n",
    "        for layer in self.layer_list:\n",
    "            y = layer(y)\n",
    "        log_s = self.log_s_layer(y)\n",
    "        t = self.t_layer(y)\n",
    "        return log_s, t\n",
    "\n",
    "\n",
    "def nn_test():\n",
    "    nn = NN(2, [256, 256])\n",
    "    x = tf.keras.Input([16, 16, 2])\n",
    "    log_s, t = nn(x)\n",
    "    # Non trainable params: -> Batch Normalization's params\n",
    "    tf.keras.Model(x, [log_s, t], name=\"nn_test\").summary()\n",
    "\n",
    "\n",
    "nn_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RealNVP Bijector\n",
    "ref. https://github.com/openai/glow/blob/master/model.py#L367-L383"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable_variables : 8\n",
      "(64, 16, 16, 4) (64, 16, 16, 4) (64,)\n"
     ]
    }
   ],
   "source": [
    "class RealNVP(tfb.Bijector):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape,\n",
    "        forward_min_event_ndims=3,\n",
    "        validate_args: bool = False,\n",
    "        name=\"real_nvp\",\n",
    "        n_hidden=[512, 512],\n",
    "        **kargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_shape: \n",
    "                input_shape, \n",
    "                ex. [28, 28, 3] (image) [2] (x-y vector)\n",
    "            forward_min_event_ndims:\n",
    "                this bijector do \n",
    "                1. element-wize quantities => 0\n",
    "                2. vector-wize quantities => 1\n",
    "                3. matrix-wize quantities => 2\n",
    "                4. tensor-wize quantities => 3\n",
    "            n_hidden:\n",
    "                see. class NN\n",
    "            **kargs:\n",
    "                see. class NN\n",
    "                you can inuput NN's layers parameter here.\n",
    "        \"\"\"\n",
    "        super(RealNVP, self).__init__(\n",
    "            validate_args=validate_args,\n",
    "            forward_min_event_ndims=forward_min_event_ndims,\n",
    "            name=name,\n",
    "        )\n",
    "\n",
    "        assert input_shape[-1] % 2 == 0\n",
    "        self.input_shape = input_shape\n",
    "        nn_layer = NN(input_shape[-1] // 2, n_hidden)\n",
    "        nn_input_shape = input_shape.copy()\n",
    "        nn_input_shape[-1] = input_shape[-1] // 2\n",
    "        x = tf.keras.Input(nn_input_shape)\n",
    "        log_s, t = nn_layer(x)\n",
    "        self.nn = Model(x, [log_s, t], name=self.name + \"/nn\")\n",
    "\n",
    "    def _forward(self, x):\n",
    "        x_a, x_b = tf.split(x, 2, axis=-1)\n",
    "        y_b = x_b\n",
    "        log_s, t = self.nn(x_b)\n",
    "        s = tf.exp(log_s)\n",
    "        y_a = s * x_a + t\n",
    "        y = tf.concat([y_a, y_b], axis=-1)\n",
    "        return y\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        y_a, y_b = tf.split(y, 2, axis=-1)\n",
    "        x_b = y_b\n",
    "        log_s, t = self.nn(y_b)\n",
    "        s = tf.exp(log_s)\n",
    "        x_a = (y_a - t) / s\n",
    "        x = tf.concat([x_a, x_b], axis=-1)\n",
    "        return x\n",
    "\n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        _, x_b = tf.split(x, 2, axis=-1)\n",
    "        log_s, t = self.nn(x_b)\n",
    "        return tf.reduce_sum(log_s)\n",
    "\n",
    "\n",
    "def realnvp_test():\n",
    "    realnvp = RealNVP(input_shape=[16, 16, 4], n_hidden=[256, 256])\n",
    "    x = tf.keras.Input([16, 16, 4])\n",
    "    y = realnvp.forward(x)\n",
    "    print(\"trainable_variables :\", len(realnvp.trainable_variables))\n",
    "\n",
    "    flow = tfd.TransformedDistribution(\n",
    "        event_shape=[16, 16, 4],\n",
    "        distribution=tfd.Normal(loc=0.0, scale=1.0),\n",
    "        bijector=realnvp,\n",
    "    )\n",
    "    x = flow.sample(64)\n",
    "    y = realnvp.inverse(x)\n",
    "    log_prob = flow.log_prob(y)\n",
    "    print(\n",
    "        x.shape,\n",
    "        y.shape,\n",
    "        log_prob.shape,\n",
    "    )\n",
    "\n",
    "\n",
    "realnvp_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BatchNormalization Layer\n",
    "\n",
    "ref. tensorflow_probability/bijector/BatchNormalization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation Bijector\n",
    "Reverse by Channel dims.\n",
    "In Glow, it improve this layer to Invertible 1x1 convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-1.4077907, shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1114, shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RevPermute(tfb.Bijector):\n",
    "    def __init__(\n",
    "        self,\n",
    "        axis=[-1],\n",
    "        forward_min_event_ndims=0,\n",
    "        validate_args=False,\n",
    "        name=\"RevPermute\",\n",
    "    ):\n",
    "        super(RevPermute, self).__init__(\n",
    "            forward_min_event_ndims=forward_min_event_ndims,\n",
    "            validate_args=validate_args,\n",
    "            name=name,\n",
    "            is_constant_jacobian=True\n",
    "        )\n",
    "        self._axis = axis\n",
    "\n",
    "    @property\n",
    "    def axis(self):\n",
    "        return self._axis\n",
    "\n",
    "    def _forward(self, x):\n",
    "        return tf.reverse(x, self.axis)\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        return tf.reverse(y, self.axis)\n",
    "\n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        return tf.constant(0.0, dtype=x.dtype)\n",
    "\n",
    "    def _inverse_log_det_jacobian(self, y):\n",
    "        return tf.constant(0.0, dtype=y.dtype)\n",
    "\n",
    "\n",
    "def test_revPermute():\n",
    "    revPermute = RevPermute()\n",
    "    x = tf.keras.Input([16, 16, 4])\n",
    "    y = revPermute.forward(x)\n",
    "    # tf.keras.Model(x, y).summary()\n",
    "\n",
    "    x = tf.random.normal([2, 16, 16, 4])\n",
    "    y = revPermute.forward(x)\n",
    "    z = revPermute.inverse(y)\n",
    "    flow = tfd.TransformedDistribution(distribution=target_dist, bijector=revPermute)\n",
    "    print(tf.reduce_mean(flow.log_prob(tf.random.normal([2, 16, 16, 3]))))\n",
    "    return tf.reduce_sum(z - x)\n",
    "\n",
    "\n",
    "test_revPermute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeeze Bijector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "(64, 16, 16, 2) (64, 8, 8, 8) (64,)\n"
     ]
    }
   ],
   "source": [
    "class Squeeze3D(tfb.Bijector):\n",
    "    def __init__(\n",
    "        self,\n",
    "        factor=2,\n",
    "        forward_min_event_ndims=0,\n",
    "        inverse_min_event_ndims=0,\n",
    "        validate_args=False,\n",
    "        name=\"Squeeze\",\n",
    "    ):\n",
    "        self._factor = factor\n",
    "        super(Squeeze3D, self).__init__(\n",
    "            forward_min_event_ndims=forward_min_event_ndims,\n",
    "            inverse_min_event_ndims=inverse_min_event_ndims,\n",
    "            name=name,\n",
    "            is_constant_jacobian=True\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def factor(self):\n",
    "        return self._factor\n",
    "\n",
    "    def _forward(self, x):\n",
    "        (H, W, C) = x.shape[1:]\n",
    "        batch_size = tf.shape(x)[0:1]\n",
    "        tmp_shape = tf.concat(\n",
    "            [\n",
    "                batch_size,\n",
    "                (H // self.factor, self.factor, W // self.factor, self.factor, C),\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "        output_shape = tf.concat(\n",
    "            [batch_size, (H // self.factor, W // self.factor, C * self.factor ** 2)],\n",
    "            axis=0,\n",
    "        )\n",
    "        y = tf.reshape(x, tmp_shape)\n",
    "        y = tf.transpose(y, [0, 1, 3, 5, 2, 4])\n",
    "        y = tf.reshape(y, output_shape)\n",
    "        return y\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        (H, W, C) = y.shape[1:]\n",
    "        batch_size = tf.shape(y)[0:1]\n",
    "        tmp_shape = tf.concat(\n",
    "            [batch_size, (H, W, C // self.factor ** 2, self.factor, self.factor)], axis=0\n",
    "        )\n",
    "        output_shape = tf.concat(\n",
    "            [batch_size, (H * self.factor, W * self.factor, C // self.factor ** 2)], axis=0\n",
    "        )\n",
    "        x = tf.reshape(y, tmp_shape)\n",
    "        x = tf.transpose(x, [0, 1, 4, 2, 5, 3])\n",
    "        x = tf.reshape(x, output_shape)\n",
    "        return x\n",
    "\n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        return tf.constant(0.0, dtype=x.dtype)\n",
    "\n",
    "\n",
    "def test_squeeze3D():\n",
    "    factor = 2\n",
    "    x = tf.Variable([[[1, 2, 5, 6], [3, 4, 7, 8], [9, 10, 13, 14], [11, 12, 15, 16]]])\n",
    "    x = tf.expand_dims(x, axis=-1)\n",
    "    squeeze3d = Squeeze3D()\n",
    "    y = squeeze3d.forward(x)\n",
    "    z = squeeze3d.inverse(y)\n",
    "    print(tf.reduce_sum(x - z))\n",
    "    \n",
    "    flow = tfd.TransformedDistribution(\n",
    "        event_shape=[16, 16, 2],\n",
    "        distribution=tfd.Normal(loc=0., scale=1.),\n",
    "        bijector=squeeze3d\n",
    "    )\n",
    "    x = tf.random.normal([64, 16, 16, 2])\n",
    "    y = flow.bijector.forward(x)\n",
    "    log_prob = flow.log_prob(y)\n",
    "    print(x.shape, y.shape, log_prob.shape)\n",
    "    \n",
    "\n",
    "test_squeeze3D()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-Scale Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,) tf.Tensor(1455.3013, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def gen_flow_chain(level=3):\n",
    "    flow_chain_list = []\n",
    "    for i in range(level):\n",
    "        flow_chain_list.append(Squeeze3D())\n",
    "        flow_chain_list.append(tfb.BatchNormalization())\n",
    "        flow_chain_list.append(RevPermute()),\n",
    "        flow_chain_list.append(RealNVP(input_shape=[16, 16, 4], n_hidden=[256, 256])),\n",
    "        flow_chain_list.append(tfb.Invert(Squeeze3D()))\n",
    "    return tfb.Chain(list(reversed(flow_chain_list)))  \n",
    "    \n",
    "flow_bijector = gen_flow_chain()\n",
    "\n",
    "flow = tfd.TransformedDistribution(\n",
    "    event_shape=[32, 32, 1],\n",
    "    distribution=tfd.Normal(loc=0.0, scale=1.0),\n",
    "    bijector=tfb.Invert(flow_bijector),\n",
    ")\n",
    "\n",
    "x = tf.random.normal([64, 32, 32, 1])\n",
    "log_prob = flow.log_prob(x)\n",
    "print(log_prob.shape, -tf.reduce_mean(log_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Multi-Scale Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blockwise Bijector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=18997, shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ref: https://github.com/tensorflow/probability/blob/master/tensorflow_probability/python/bijectors/blockwise.py\n",
    "class Blockwise3D(tfb.Bijector):\n",
    "    def __init__(self, bijectors, block_sizes=None, validate_args=False, name=None):\n",
    "        if not name:\n",
    "            name = \"blockwise3D_of_\" + \"_and_\".join([b.name for b in bijectors])\n",
    "            name = name.replace(\"/\", \"\")\n",
    "        super(Blockwise3D, self).__init__(\n",
    "            # ???\n",
    "            forward_min_event_ndims=3,\n",
    "            validate_args=validate_args,\n",
    "            name=name,\n",
    "        )\n",
    "        self._bijectors = bijectors\n",
    "        self._block_sizes = block_sizes\n",
    "\n",
    "    @property\n",
    "    def bijectors(self):\n",
    "        return self._bijectors\n",
    "\n",
    "    @property\n",
    "    def block_sizes(self):\n",
    "        return self._block_sizes\n",
    "\n",
    "    def _forward(self, x):\n",
    "        split_x = (\n",
    "            tf.split(x, len(self.bijectors), axis=-1)\n",
    "            if self.block_sizes is None\n",
    "            else tf.split(x, self.block_sizes, axis=-1)\n",
    "        )\n",
    "        split_y = [b.forward(x_) for b, x_ in zip(self.bijectors, split_x)]\n",
    "        y = tf.concat(split_y, axis=-1)\n",
    "        return y\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        split_y = (\n",
    "            tf.split(y, len(self.bijectors), axis=-1)\n",
    "            if self.block_sizes is None\n",
    "            else tf.split(y, self.block_sizes, axis=-1)\n",
    "        )\n",
    "        split_x = [b.inverse(y_) for b, y_ in zip(self.bijectors, split_y)]\n",
    "        x = tf.concat(split_x, axis=-1)\n",
    "        return x\n",
    "\n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        split_x = (\n",
    "            tf.split(x, len(self.bijectors), axis=-1)\n",
    "            if self.block_sizes is None\n",
    "            else tf.split(x, self.block_sizes, axis=-1)\n",
    "        )\n",
    "        fldjs = [\n",
    "            # ???\n",
    "            b.forward_log_det_jacobian(x_, event_ndims=3)\n",
    "            for b, x_ in zip(self.bijectors, split_x)\n",
    "        ]\n",
    "        return sum(fldjs)\n",
    "\n",
    "    def _inverse_log_det_jacobian(self, y):\n",
    "        split_y = (\n",
    "            tf.split(y, len(self.bijectors), axis=-1)\n",
    "            if self.block_sizes is None\n",
    "            else tf.split(y, self.block_sizes, axis=-1)\n",
    "        )\n",
    "        ildjs = [\n",
    "            b.inverse_log_det_jacobian(y_, event_ndims=3)\n",
    "            for b, y_ in zip(self.bijectors, split_y)\n",
    "        ]\n",
    "        return sum(ildjs)\n",
    "\n",
    "\n",
    "def test_blockwise3D():\n",
    "    blockwise3D = Blockwise3D(\n",
    "        bijectors=[\n",
    "            tfb.Identity(),\n",
    "            RealNVP(input_shape=[16, 16, 2], n_hidden=[256, 256]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    x = tf.keras.Input([16, 16, 4])\n",
    "    y = blockwise3D.forward(x)\n",
    "    # tf.keras.Model(x, y).summary()\n",
    "\n",
    "    x = tf.random.normal([3, 16, 16, 4])\n",
    "    y = blockwise3D.forward(x)\n",
    "    z = blockwise3D.inverse(y)\n",
    "    return tf.reduce_sum(z - x)\n",
    "\n",
    "\n",
    "test_blockwise3D()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Scale Model\n",
    "\n",
    "For simplicity, we use below model.\n",
    "0. Squeeze $[32, 32, 1] \\rightarrow [16, 16, 4]$ \n",
    "1. Flow-step\n",
    "2. if not last Flow-step    \n",
    "    BlockWise3D \n",
    "        1. Identity\n",
    "        2. 0 へ\n",
    "3. Unsqueeze $[16, 16, 4] \\rightarrow [32, 32, 1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, indicates the transition of L=3.    \n",
    "In below code, export RealNVP's model architecture to png file.\n",
    "\n",
    "![](../img//multi-scale-arch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3489, shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_flowSteps(\n",
    "    # for realnvp\n",
    "    input_shape: list,\n",
    "    n_hidden: list = [256, 256],\n",
    "    # for flowStep\n",
    "    k=2,\n",
    "    forward_min_event_ndims: int = 3,\n",
    "    validate_args: bool = False,\n",
    "    name: str = \"flow_step\",\n",
    "):\n",
    "    flow_step_list = []\n",
    "    for i in range(k):\n",
    "        flow_step_list.append(tfb.BatchNormalization(validate_args=validate_args))\n",
    "        flow_step_list.append(RevPermute(validate_args=validate_args)),\n",
    "        flow_step_list.append(\n",
    "            RealNVP(\n",
    "                input_shape=input_shape,\n",
    "                n_hidden=n_hidden,\n",
    "                validate_args=validate_args,\n",
    "                name=\"{}_{}/realnvp\".format(name, i),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    flowSteps = tfb.Chain(\n",
    "        list(reversed(flow_step_list)), validate_args=validate_args, name=name\n",
    "    )\n",
    "    return flowSteps\n",
    "\n",
    "\n",
    "def test_gen_flowSteps():\n",
    "    flowSteps = gen_flowSteps(\n",
    "        k=2, input_shape=[16, 16, 4], forward_min_event_ndims=0, name=\"flowstep_0\"\n",
    "    )\n",
    "    x = tf.keras.Input([16, 16, 4])\n",
    "    y = flowSteps(x)\n",
    "    # tf.keras.Model(x, y).summary()\n",
    "\n",
    "    x = tf.random.normal([6, 16, 16, 4])\n",
    "    y = flowSteps.forward(x)\n",
    "    z = flowSteps.inverse(y)\n",
    "    return tf.reduce_sum(z - x)\n",
    "\n",
    "\n",
    "test_gen_flowSteps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5637, shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_flow(input_shape, level=3, flow_step_args: dict = None):\n",
    "    def _gen_input_shapes(input_shape, level):\n",
    "        input_shape = input_shape\n",
    "        input_shapes = []\n",
    "        for i in range(level):\n",
    "            input_shape = [\n",
    "                input_shape[0] // 2,\n",
    "                input_shape[1] // 2,\n",
    "                input_shape[2] * 4 - i * 8,\n",
    "            ]\n",
    "            input_shapes.append(input_shape)\n",
    "        return input_shapes\n",
    "\n",
    "    input_shapes = _gen_input_shapes(input_shape, level)\n",
    "\n",
    "    def _add_flow(_input_shapes, flow_step_args):\n",
    "        flow_lists = []\n",
    "        flow_lists.append(\n",
    "            Squeeze3D(name=\"Squeeze_{}\".format(level - len(_input_shapes)))\n",
    "        )\n",
    "        flowSteps = gen_flowSteps(\n",
    "           k=2,\n",
    "           input_shape=_input_shapes[0],\n",
    "           name=\"Flowsteps_{}\".format(level - len(_input_shapes)),\n",
    "        )\n",
    "        flow_lists.append(flowSteps)\n",
    "        if len(_input_shapes) != 1:\n",
    "            flow_lists.append(\n",
    "                Blockwise3D(\n",
    "                    [\n",
    "                        tfb.Identity(),\n",
    "                        tfb.Chain(\n",
    "                            list(reversed(_add_flow(_input_shapes[1:], flow_step_args)))\n",
    "                        ),\n",
    "                    ],\n",
    "                    name=\"Blockwise3D_{}\".format(level - len(_input_shapes)),\n",
    "                )\n",
    "            )\n",
    "        flow_lists.append(\n",
    "            tfb.Invert(\n",
    "                Squeeze3D(name=\"Unsqueeze_{}\".format(level - len(_input_shapes)))\n",
    "            )\n",
    "        )\n",
    "        return flow_lists\n",
    "\n",
    "    return tfb.Chain(list(reversed(_add_flow(input_shapes, level))))\n",
    "\n",
    "\n",
    "def test_gen_flow():\n",
    "    flow = gen_flow([32, 32, 1])\n",
    "    print(len(flow.trainable_variables))\n",
    "    x = tf.keras.Input([32, 32, 1])\n",
    "    y = flow.forward(x)\n",
    "    # tf.keras.Model(x, y).summary()\n",
    "    tf.keras.utils.plot_model(\n",
    "        tf.keras.Model(x, y), show_shapes=True, to_file=\"realnvp.png\"\n",
    "    )\n",
    "    x = tf.random.normal([3, 32, 32, 1])\n",
    "    y = flow.forward(x)\n",
    "    z = flow.inverse(y) \n",
    "    return tf.reduce_sum(z - x)\n",
    "\n",
    "test_gen_flow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TransformDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "trainable_variables:  48\n"
     ]
    }
   ],
   "source": [
    "flow_bijector = gen_flow([32, 32, 1])\n",
    "print(len(flow_bijector.trainable_variables))\n",
    "flow = tfd.TransformedDistribution(\n",
    "    event_shape =[32, 32, 1],\n",
    "    distribution=tfd.Normal(loc=0.0, scale=1.0),\n",
    "    bijector=flow_bijector\n",
    ")\n",
    "print('trainable_variables: ', len(flow.bijector.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss, Optimizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -r checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def loss():\n",
    "    return - tf.reduce_mean(flow.log_prob(targets['img']))\n",
    "\n",
    "\n",
    "optimizer = tf.optimizers.Adam(learning_rate=1e-4) \n",
    "# log = tf.summary.create_file_writer('checkpoints')\n",
    "avg_loss = tf.keras.metrics.Mean(name='loss', dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 32, 32, 1)\n",
      "tf.Tensor(826.2821, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=64\n",
    "train_dataset = train_dataset_raw.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "for target in train_dataset.take(1):\n",
    "    targets = target\n",
    "print(targets['img'].shape)\n",
    "with tf.GradientTape() as tape:\n",
    "    log_prob_loss = loss()\n",
    "grads = tape.gradient(log_prob_loss, flow.trainable_variables)\n",
    "print(log_prob_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=1000> Loss -113248.062500\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=2000> Loss -113989.187500\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=3000> Loss -114157.593750\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=4000> Loss -114258.070312\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=5000> Loss -114342.117188\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=6000> Loss -114492.078125\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=7000> Loss -114595.812500\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=8000> Loss -114729.562500\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=9000> Loss -114821.367188\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=10000> Loss -114956.937500\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=11000> Loss -115009.398438\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=12000> Loss -115156.687500\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=13000> Loss -115213.570312\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=14000> Loss -115255.046875\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=15000> Loss -115288.117188\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=16000> Loss -115313.742188\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=17000> Loss -115337.671875\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=18000> Loss -115357.023438\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=19000> Loss -115373.953125\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=20000> Loss -115389.796875\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=21000> Loss -115401.953125\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=22000> Loss -115414.968750\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=23000> Loss -115426.367188\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=24000> Loss -115438.609375\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=25000> Loss -115447.476562\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=26000> Loss -115455.203125\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=27000> Loss -115465.437500\n",
      "Step <tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=28000> Loss -115473.296875\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for targets in train_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            log_prob_loss = loss()\n",
    "        grads = tape.gradient(log_prob_loss, flow.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, flow.trainable_variables))\n",
    "        avg_loss.update_state(log_prob_loss)\n",
    "        if tf.equal(optimizer.iterations % 1000, 0):\n",
    "            print(\"Step {} Loss {:.6f}\".format(optimizer.iterations, avg_loss.result()))\n",
    "        if tf.equal(optimizer.iterations % 100, 0):\n",
    "            # with log.as_default():\n",
    "            #     tf.summary.scalar(\"loss\", avg_loss.result(), step=optimizer.iterations)\n",
    "            #     avg_loss.reset_states()\n",
    "            avg_loss.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset_raw.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log probability:  -2.404663\n",
      "inv mean:  -1.7276034e-07  std:  1.7237891\n",
      "re:trg mean:  -0.79402995  std:  0.5574867\n",
      "(1, 32, 32, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f131d70c210>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "for targets in test_dataset.take(1):\n",
    "    trg = targets[\"img\"]\n",
    "    inv = flow.bijector.inverse(trg)\n",
    "    re_trg = flow.bijector.forward(inv)\n",
    "\n",
    "print('log probability: ', tf.reduce_mean(tfd.Normal(0., 1.).log_prob(inv)).numpy())\n",
    "print(\"inv mean: \", tf.reduce_mean(inv).numpy(), \" std: \", tf.math.reduce_std(inv).numpy())\n",
    "print(\"re:trg mean: \", tf.reduce_mean(re_trg).numpy(), \" std: \", tf.math.reduce_std(re_trg).numpy())\n",
    "\n",
    "re_inv = np.array([(inv[0] + inv[1]) / 2.0])\n",
    "print(re_inv.shape)\n",
    "re_re_trg = flow.bijector.forward(re_inv)\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 1)\n",
    "ax.imshow(tf.squeeze(trg[0], axis=-1), aspect=\"auto\", cmap=\"gray_r\")\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 4)\n",
    "ax.imshow(tf.squeeze(re_trg[0], axis=-1), aspect=\"auto\", cmap=\"gray_r\")\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 2)\n",
    "ax.imshow(tf.squeeze(trg[1], axis=-1), aspect=\"auto\", cmap=\"gray_r\")\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 5)\n",
    "ax.imshow(tf.squeeze(re_trg[1], axis=-1), aspect=\"auto\", cmap=\"gray_r\")\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 3)\n",
    "ax.imshow(tf.squeeze(re_inv[0], axis=-1), aspect=\"auto\", cmap=\"gray_r\")\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 6)\n",
    "ax.imshow(tf.squeeze(re_re_trg[0], axis=-1), aspect=\"auto\", cmap=\"gray_r\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
